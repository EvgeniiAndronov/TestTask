1. Что было сделано.
   Был реализован парсер, который собирает со страницы карточки с высказываниями, содержащие в себе такие  параметры как:
   - Текст высказывания
   - Автор высказывания
   - Тег высказывания
   Парсер работает синхронно, для стартаего работы, нам необходимо при запуске из командной строки, указать номера страниц через пробел, которые мы хотим спарсить в json файл, пример запуска:
python3 main.py 1 2 3 4 10
    Была прописана простая защита от пустых или отсутвующих страниц в виде ожидания 200 кода при запросе, а так же, что карточки вернулись целыми(данные пришли, в противном случае возвращается None)
2. Откуда были получены данные
    Данные были получены с сайта https://quotes.toscrape.com/, а именно из кода html
3. Как осуществлялся сбор
    Был реализован запрос к нужной странице сайта, получен код html данной страницы, откуда и была собрана нужная нам информация
4. Почему был выбран тот или иной метод/инструмент, а не другой
   Для работы с html кодом, который нужно обработать по конкретным тегам, можно использовать несколько библиотек, в частности регулярные выражения, однако прописывать регулярные выражения в данном случае
было бы слишком длого, я использовал библиотеку bs4, по трем причинам, а именно:
    - легко читается код
    - достаточно быстро работает
    - я очень много реализовал парсеров с использованием данной библиотеки

